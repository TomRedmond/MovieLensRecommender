{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "Our objective is to predict a new venue's popularity from information available\n",
    "when the venue opens.  We will do this by machine learning from a dataset of\n",
    "venue popularities provided by Yelp.  The dataset contains meta data about the\n",
    "venue (where it is located, the type of food served, etc ...).  It also\n",
    "contains a star rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'data\\\\yelp_train_academic_dataset_business.json' does not exist: b'data\\\\yelp_train_academic_dataset_business.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-19f142cc87ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"yelp_train_academic_dataset_business.json\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'data\\\\yelp_train_academic_dataset_business.json' does not exist: b'data\\\\yelp_train_academic_dataset_business.json'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import dill\n",
    "\n",
    "class mypredictor():\n",
    "    def __init__(self, inp_datafile_name=os.path.join(\"data\",\"q1_inp_for_model.csv\")):\n",
    "        self.data=pd.read_csv(inp_datafile_name)\n",
    "        self.average=self.data['stars'].mean()\n",
    "\n",
    "    def predict(self, input_dict):\n",
    "        input_record=input_dict\n",
    "        input_city=input_record['city']\n",
    "        if input_city in self.data.index:\n",
    "            return self.data.loc[input_city][0]\n",
    "        else:\n",
    "            return self.average\n",
    "\n",
    "filename=os.path.join(\"data\",\"yelp_train_academic_dataset_business.json\")\n",
    "data=pd.read_csv(filename)\n",
    "\n",
    "\n",
    "q1_data=pd.DataFrame({\"city\":data['city'],\"stars\":data['stars']})\n",
    "q1_data.city[q1_data.city=='chandler'] = 'Chandler' # dealing with inconsistent capitalization for one of the cities\n",
    "q1_data=q1_data.sort_values(by=\"city\",ascending=True)\n",
    "\n",
    "q1_ans=q1_data.groupby(['city']).mean()\n",
    "q1_ans=q1_ans.reset_index()\n",
    "\n",
    "q1_ans.to_csv(os.path.join(\"data\",\"q1_inp_for_model.csv\"), encoding='utf-8', index=False)  \n",
    "\n",
    "dill.dump(mypredictor, open(os.path.join(\"data\",\"q1dill\"), \"wb\"))\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import ujson\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dill\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "#from sklearn import grid_search\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'grid_search' from 'sklearn' (C:\\Users\\Soha\\Anaconda3\\lib\\site-packages\\sklearn\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0a91955bf4c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'grid_search' from 'sklearn' (C:\\Users\\Soha\\Anaconda3\\lib\\site-packages\\sklearn\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, grid_search, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('yelp_train_academic_dataset_business.json.gz', 'rb') as f:\n",
    "    file_content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('yelp_train_academic_dataset_business.json.gz', 'rb') as f:\n",
    "    file_content = f.read()\n",
    "a = ujson.dumps(file_content,encode_html_chars=True,reject_bytes= False)\n",
    "b = ujson.loads(a)\n",
    "b = b.replace('\\n',',').replace('&','and')\n",
    "List = '['+b[:-1]+']'\n",
    "Data = ujson.loads(List)\n",
    "df = pd.DataFrame(Data)\n",
    "\n",
    "#Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA SAMPLE\n",
    "test_json = [\n",
    "    {\"business_id\": \"vcNAWiLM4dR7D2nwwJ7nCA\", \"full_address\": \"4840 E Indian School Rd\\nSte 101\\nPhoenix, AZ 85018\", \"hours\": {\"Tuesday\": {\"close\": \"17:00\", \"open\": \"08:00\"}, \"Friday\": {\"close\": \"17:00\", \"open\": \"08:00\"}, \"Monday\": {\"close\": \"17:00\", \"open\": \"08:00\"}, \"Wednesday\": {\"close\": \"17:00\", \"open\": \"08:00\"}, \"Thursday\": {\"close\": \"17:00\", \"open\": \"08:00\"}}, \"open\": True, \"categories\": [\"Doctors\", \"Health & Medical\"], \"city\": \"Phoenix\", \"review_count\": 7, \"name\": \"Eric Goldberg, MD\", \"neighborhoods\": [], \"longitude\": -111.98375799999999, \"state\": \"AZ\", \"stars\": 3.5, \"latitude\": 33.499313000000001, \"attributes\": {\"By Appointment Only\": True}, \"type\": \"business\"},\n",
    "    {\"business_id\": \"vcNAWiLM4dR7D2nwwJ7nCA\", \"full_address\": \"4840 E Indian School Rd\\nSte 101\\nPhoenix, AZ 85018\", \"hours\": {\"Tuesday\": {\"close\": \"17:00\", \"open\": \"08:00\"}, \"Friday\": {\"close\": \"17:00\", \"open\": \"08:00\"}, \"Monday\": {\"close\": \"17:00\", \"open\": \"08:00\"}, \"Wednesday\": {\"close\": \"17:00\", \"open\": \"08:00\"}, \"Thursday\": {\"close\": \"17:00\", \"open\": \"08:00\"}}, \"open\": True, \"categories\": [\"Doctors\", \"Health & Medical\"], \"city\": \"ABC\", \"review_count\": 7, \"name\": \"Eric Goldberg, MD\", \"neighborhoods\": [], \"longitude\": -111.98375799999999, \"state\": \"AZ\", \"stars\": 3.5, \"latitude\": 33.499313000000001, \"attributes\": {\"By Appointment Only\": True}, \"type\": \"business\"},\n",
    "    {\"business_id\": \"JwUE5GmEO-sH1FuwJgKBlQ\", \"full_address\": \"6162 US Highway 51\\nDe Forest, WI 53532\", \"hours\": {}, \"open\": True, \"categories\": [\"Restaurants\"], \"city\": \"De Forest\", \"review_count\": 26, \"name\": \"Pine Cone Restaurant\", \"neighborhoods\": [], \"longitude\": -89.335843999999994, \"state\": \"WI\", \"stars\": 4.0, \"latitude\": 43.238892999999997, \"attributes\": {\"Take-out\": True, \"Good For\": {\"dessert\": False, \"latenight\": False, \"lunch\": True, \"dinner\": False, \"breakfast\": False, \"brunch\": False}, \"Caters\": False, \"Noise Level\": \"average\", \"Takes Reservations\": False, \"Delivery\": False, \"Ambience\": {\"romantic\": False, \"intimate\": False, \"touristy\": False, \"hipster\": False, \"divey\": False, \"classy\": False, \"trendy\": False, \"upscale\": False, \"casual\": False}, \"Parking\": {\"garage\": False, \"street\": False, \"validated\": False, \"lot\": True, \"valet\": False}, \"Has TV\": True, \"Outdoor Seating\": False, \"Attire\": \"casual\", \"Alcohol\": \"none\", \"Waiter Service\": True, \"Accepts Credit Cards\": True, \"Good for Kids\": True, \"Good For Groups\": True, \"Price Range\": 1}, \"type\": \"business\"},\n",
    "    {\"business_id\": \"uGykseHzyS5xAMWoN6YUqA\", \"full_address\": \"505 W North St\\nDe Forest, WI 53532\", \"hours\": {\"Monday\": {\"close\": \"22:00\", \"open\": \"06:00\"}, \"Tuesday\": {\"close\": \"22:00\", \"open\": \"06:00\"}, \"Friday\": {\"close\": \"22:00\", \"open\": \"06:00\"}, \"Wednesday\": {\"close\": \"22:00\", \"open\": \"06:00\"}, \"Thursday\": {\"close\": \"22:00\", \"open\": \"06:00\"}, \"Sunday\": {\"close\": \"21:00\", \"open\": \"06:00\"}, \"Saturday\": {\"close\": \"22:00\", \"open\": \"06:00\"}}, \"open\": True, \"categories\": [\"American (Traditional)\", \"Restaurants\"], \"city\": \"De Forest\", \"review_count\": 16, \"name\": \"Deforest Family Restaurant\", \"neighborhoods\": [], \"longitude\": -89.353437, \"state\": \"WI\", \"stars\": 4.0, \"latitude\": 43.252267000000003, \"attributes\": {\"Take-out\": True, \"Good For\": {\"dessert\": False, \"latenight\": False, \"lunch\": False, \"dinner\": False, \"breakfast\": False, \"brunch\": True}, \"Caters\": False, \"Noise Level\": \"quiet\", \"Takes Reservations\": False, \"Delivery\": False, \"Parking\": {\"garage\": False, \"street\": False, \"validated\": False, \"lot\": True, \"valet\": False}, \"Has TV\": True, \"Outdoor Seating\": False, \"Attire\": \"casual\", \"Ambience\": {\"romantic\": False, \"intimate\": False, \"touristy\": False, \"hipster\": False, \"divey\": False, \"classy\": False, \"trendy\": False, \"upscale\": False, \"casual\": True}, \"Waiter Service\": True, \"Accepts Credit Cards\": True, \"Good for Kids\": True, \"Good For Groups\": True, \"Price Range\": 1}, \"type\": \"business\"},\n",
    "    {\"business_id\": \"LRKJF43s9-3jG9Lgx4zODg\", \"full_address\": \"4910 County Rd V\\nDe Forest, WI 53532\", \"hours\": {\"Monday\": {\"close\": \"22:00\", \"open\": \"10:30\"}, \"Tuesday\": {\"close\": \"22:00\", \"open\": \"10:30\"}, \"Friday\": {\"close\": \"22:00\", \"open\": \"10:30\"}, \"Wednesday\": {\"close\": \"22:00\", \"open\": \"10:30\"}, \"Thursday\": {\"close\": \"22:00\", \"open\": \"10:30\"}, \"Sunday\": {\"close\": \"22:00\", \"open\": \"10:30\"}, \"Saturday\": {\"close\": \"22:00\", \"open\": \"10:30\"}}, \"open\": True, \"categories\": [\"Food\", \"Ice Cream & Frozen Yogurt\", \"Fast Food\", \"Restaurants\"], \"city\": \"De Forest\", \"review_count\": 7, \"name\": \"Culver's\", \"neighborhoods\": [], \"longitude\": -89.374983, \"state\": \"WI\", \"stars\": 4.5, \"latitude\": 43.251044999999998, \"attributes\": {\"Take-out\": True, \"Wi-Fi\": \"free\", \"Takes Reservations\": False, \"Delivery\": False, \"Parking\": {\"garage\": False, \"street\": False, \"validated\": False, \"lot\": True, \"valet\": False}, \"Wheelchair Accessible\": True, \"Attire\": \"casual\", \"Accepts Credit Cards\": True, \"Good For Groups\": True, \"Price Range\": 1}, \"type\": \"business\"},\n",
    "    {\"business_id\": \"RgDg-k9S5YD_BaxMckifkg\", \"full_address\": \"631 S Main St\\nDe Forest, WI 53532\", \"hours\": {\"Monday\": {\"close\": \"22:00\", \"open\": \"11:00\"}, \"Tuesday\": {\"close\": \"22:00\", \"open\": \"11:00\"}, \"Friday\": {\"close\": \"22:30\", \"open\": \"11:00\"}, \"Wednesday\": {\"close\": \"22:00\", \"open\": \"11:00\"}, \"Thursday\": {\"close\": \"22:00\", \"open\": \"11:00\"}, \"Sunday\": {\"close\": \"21:00\", \"open\": \"16:00\"}, \"Saturday\": {\"close\": \"22:30\", \"open\": \"11:00\"}}, \"open\": True, \"categories\": [\"Chinese\", \"Restaurants\"], \"city\": \"De Forest\", \"review_count\": 3, \"name\": \"Chang Jiang Chinese Kitchen\", \"neighborhoods\": [], \"longitude\": -89.343721700000003, \"state\": \"WI\", \"stars\": 4.0, \"latitude\": 43.2408748, \"attributes\": {\"Take-out\": True, \"Has TV\": False, \"Outdoor Seating\": False, \"Attire\": \"casual\"}, \"type\": \"business\"}\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1:city_model\n",
    "\n",
    "The venues belong to different cities.  You can image that the ratings in some\n",
    "cities are probably higher than others and use this as an estimator.\n",
    "\n",
    "Therefore,I built an estimator that uses `groupby` and `mean` to compute the\n",
    "average rating in that city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7818181818181817"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = df[['city', 'stars']]\n",
    "#tuples = [tuple(x) for x in subset.values]\n",
    "\n",
    "average_subset = subset.groupby(['city'])['stars'].mean()\n",
    "#print average_subset\n",
    "average_subset[['Anthem']][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mean estimator\n",
    "\n",
    "\n",
    "class MyEstimator(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "\n",
    "    def fit(self,data):\n",
    "        self.average = data.groupby(['city'])['stars'].mean()\n",
    "        return self\n",
    "\n",
    "    def predict(self, record):\n",
    "        city = record['city']\n",
    "        if city not in self.average.index.values:\n",
    "            self.prediction = self.average.mean()     \n",
    "        else:\n",
    "             self.prediction = self.average[[city]][0]\n",
    "        return self.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.75"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check!\n",
    "cityestimator = MyEstimator()\n",
    "cityestimator.fit(subset)\n",
    "prediction = cityestimator.predict(test_json[3])\n",
    "prediction.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.712759336095808"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cityestimator.predict(test_json[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-0972dc2caea2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcityestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'city'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Timbuktu'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-323d9763ea9d>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mcity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecord\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'city'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcity\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "cityestimator.predict([{'city': 'Timbuktu'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2. Location_model\n",
    "\n",
    "However,city-based model might not be sufficiently fine-grained.\n",
    "For example, we know that some neighborhoods are trendier than others.  We\n",
    "might consider a K Nearest Neighbors or Random Forest based on the latitude\n",
    "longitude as a way to understand neighborhood dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a dataframe\n",
    "\n",
    "lat_lon_df = df[['latitude','longitude','stars']] \n",
    "#print lat_lon_df['latitude'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a Transformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,key):\n",
    "        self.key = key\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_selector = ColumnSelector('latitude')\n",
    "lon_selector = ColumnSelector('longitude')\n",
    "latitude_list = lat_selector.transform(df)\n",
    "longitude_list =lon_selector.transform(df)\n",
    "X = []\n",
    "for i in range(0,len(latitude_list)):\n",
    "    X.append([longitude_list[i],latitude_list[i]])\n",
    "#X\n",
    "\n",
    "star_selector = ColumnSelector('stars')\n",
    "Y = star_selector.transform(df)\n",
    "#Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a knnestimator\n",
    "class knnestimator(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self):\n",
    "        self.neigh = KNeighborsRegressor(n_neighbors=2)\n",
    "        \n",
    "        \n",
    "    def fit(self,X,Y):  \n",
    "        self.parameters = {'leaf_size':range(10,41),'metric':['minkowski'],'n_neighbors':range(1,21)}\n",
    "        self.clf = GridSearchCV(self.neigh, self.parameters,cv=3)\n",
    "        self.clf.fit(X, Y)\n",
    "        self.best_estimator = self.clf.best_estimator_ \n",
    "        return self.best_estimator\n",
    "\n",
    "    def predict(self, record): \n",
    "        value = self.best_estimator.predict([record['longitude'],record['latitude']])[0]\n",
    "        return value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump(q2_estimator, open(\"Q2\",\"w\")) \n",
    "q2_estimator = dill.load(open(\"Q2\")) \n",
    "# test one case\n",
    "prediction = q2_estimator.predict(test_json[1])\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3.Categorical model\n",
    "While location is important, we could also try seeing how predictive the\n",
    "venues' category. So I built a custom transformer that massages the data so that it\n",
    "can be fed into a `sklearn.feature_extraction.DictVetorizer` which in turn\n",
    "generates a large matrix gotten by One-Hot-Encoding.  Feed this into a Linear\n",
    "Regression (and cross validate it!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a Transformer\n",
    "\n",
    "class customTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,key):\n",
    "        self.key = key\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        #select column\n",
    "        Feature = X[self.key].values.tolist()\n",
    "        category_list = []\n",
    "        feature_str = ''\n",
    "        for item in Feature:\n",
    "            for sub_item in item:\n",
    "                feature_str = feature_str+sub_item+' '   \n",
    "            category_list.append(feature_str)\n",
    "            feature_str = ''\n",
    "        self.v = TfidfVectorizer(min_df=1)\n",
    "        self.my_features = self.v.fit_transform(category_list)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        self.feature_vec = []\n",
    "        feature_str=''       \n",
    "        for item in X[self.key]:\n",
    "            feature_str = feature_str+item+' '\n",
    "        self.feature_vec.append(feature_str)\n",
    "        #v = TfidfVectorizer(min_df=1)\n",
    "        self.my_features = self.v.transform(self.feature_vec).A\n",
    "        return self.my_features\n",
    "    \n",
    "# Test customer transform\n",
    "Transformer = customTransformer('categories') \n",
    "Transform_object = Transformer.fit(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class lrEstimator(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self):\n",
    "        self.lr = linear_model.LinearRegression()  \n",
    "\n",
    "    def fit(self):    \n",
    "        self.Transformer = customTransformer('categories')\n",
    "        Transform_object = self.Transformer.fit(df)\n",
    "        X=Transform_object.my_features\n",
    "        y = Y\n",
    "        self.Q3 = self.lr.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, record): \n",
    "        X = self.Transformer.transform(record)\n",
    "        value = self.Q3.predict(X)[0]\n",
    "        return value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test estimator class\n",
    "estimator = lrEstimator()\n",
    "q3_estimator = estimator.fit()\n",
    "dill.dump(q3_estimator, open(\"Q3\",\"w\")) \n",
    "q3_estimator = dill.load(open(\"Q3\")) \n",
    "q3_estimator.predict(test_json[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4. Attribute model\n",
    "\n",
    "Venues have (potentially nested) attributes:\n",
    "```\n",
    "    {'Attire': 'casual',\n",
    "     'Accepts Credit Cards': True,\n",
    "     'Ambience': {'casual': False, 'classy': False}}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test  flatten function\n",
    "test_dic = {u'attributes': {u'Accepts Credit Cards': True,\n",
    "   u'Alcohol': u'none',\n",
    "   u'Ambience': {u'casual': False,\n",
    "    u'classy': False,\n",
    "    u'divey': False,\n",
    "    u'hipster': False,\n",
    "    u'intimate': False,\n",
    "    u'romantic': False,\n",
    "    u'touristy': False,\n",
    "    u'trendy': False,\n",
    "    u'upscale': False},\n",
    "   u'Attire': u'casual',\n",
    "   u'Caters': False,\n",
    "   u'Delivery': False,\n",
    "   u'Good For': {u'breakfast': False,\n",
    "    u'brunch': False,\n",
    "    u'dessert': False,\n",
    "    u'dinner': False,\n",
    "    u'latenight': False,\n",
    "    u'lunch': True}}}\n",
    "    \n",
    "\n",
    "def flatten_dictionary(d):\n",
    "    def items():\n",
    "        for key, value in d.items():\n",
    "            if isinstance(value, dict):\n",
    "                for subkey, subvalue in flatten_dictionary(value).items():\n",
    "                    yield key + \"_\" + subkey, subvalue\n",
    "            elif isinstance(value,bool):\n",
    "                yield key, value\n",
    "            elif isinstance(value, str):\n",
    "                yield key+'_'+value,1\n",
    "            else:\n",
    "                yield key,value\n",
    "    return dict(items())\n",
    "\n",
    "flattened = flatten_dictionary(test_dic)\n",
    "flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a flatten transformer\n",
    "\n",
    "class flattentransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,key):\n",
    "        self.key = key\n",
    "        \n",
    "    def flatten_dictionary(self,d):\n",
    "        def items():\n",
    "            for key, value in d.items():\n",
    "                if isinstance(value, dict):\n",
    "                    for subkey, subvalue in self.flatten_dictionary(value).items():\n",
    "                        yield key + \"_\" + subkey, subvalue\n",
    "                elif isinstance(value,bool):\n",
    "                    yield key, value\n",
    "                elif isinstance(value, str):\n",
    "                    yield key+'_'+value,1\n",
    "        return dict(items())    \n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        #select column   X is the Data\n",
    "        attribute_list = []\n",
    "        for record in X:    \n",
    "            attribute_dict = self.flatten_dictionary(record[self.key])\n",
    "            attribute_list.append(attribute_dict)\n",
    "        self.v = DictVectorizer(sparse=False)\n",
    "        self.my_features = self.v.fit_transform(attribute_list)\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        self.feature_vec = self.flatten_dictionary(X[self.key])\n",
    "        self.single_feature = self.v.transform(self.feature_vec)\n",
    "        return self.single_feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test flatten transformer\n",
    "mytransformer = flattentransformer('attributes')\n",
    "mytransformer.fit(Data).my_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define an estimator\n",
    "\n",
    "class Q4Estimator(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self):\n",
    "        self.clf = linear_model.RidgeCV(alphas=[0.1, 1.0, 10.0])  \n",
    "\n",
    "    def fit(self,):    \n",
    "        self.Transformer = flattentransformer('attributes')\n",
    "        Transform_object = self.Transformer.fit(Data)\n",
    "        X=Transform_object.my_features\n",
    "        y = Y\n",
    "        self.Q4 = self.clf.fit(X, Y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, record): \n",
    "        X = self.Transformer.transform(record)\n",
    "        value = self.Q4.predict(X)[0]\n",
    "        return value\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "q4=Q4Estimator()\n",
    "q4_estimator = q4.fit()\n",
    "dill.dump(q4_estimator,open('Q4','w'))\n",
    "q4_estimator = dill.load(open(\"Q4\")) \n",
    "q4_estimator.predict(test_json[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5. Combined Model\n",
    "\n",
    "So far I have only built models based on individual features.  I could\n",
    "obviously combine them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "class UnionTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,model_name):\n",
    "        self.estimator = dill.load(open(model_name))\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        self.prediction = self.estimator.predict(X)\n",
    "        return self.prediction\n",
    "\n",
    "    \n",
    "# Define an q5Estimator\n",
    "class Q5Estimator(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self):\n",
    "        self.lr5 = linear_model.RidgeCV(alphas=[0.1, 1.0, 10.0])  \n",
    "\n",
    "    def fit(self,X):    \n",
    "        self.uniontransformer1 = UnionTransformer(\"city_model\")\n",
    "        self.uniontransformer2 = UnionTransformer(\"Q2\")\n",
    "        self.uniontransformer3 = UnionTransformer(\"Q3\")\n",
    "        self.uniontransformer4 = UnionTransformer(\"Q4\")\n",
    "        self.combined_features = FeatureUnion([\n",
    "                                 (\"uf1\", self.uniontransformer1), (\"uf2\", self.uniontransformer2),\\\n",
    "                                 (\"uf3\",self.uniontransformer3),(\"uf4\", self.uniontransformer4)\n",
    "                                 ])\n",
    "        X_feature_mat=[]\n",
    "        Y_label_list = []\n",
    "        for item in X:\n",
    "            X_features = self.combined_features.transform(item)     \n",
    "            X_feature_mat.append(X_features)\n",
    "            Y_label_list.append(item['stars'])\n",
    "        #print item\n",
    "        #print X_features\n",
    "        self.q5_estimator = self.lr5.fit(X_feature_mat,Y_label_list)\n",
    "        return self\n",
    "\n",
    "    def predict(self, record): \n",
    "        X = self.combined_features.transform(record)\n",
    "        value = self.q5_estimator.predict(X)[0]\n",
    "        return value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_estimator = Q5Estimator()\n",
    "q5_estimator = full_estimator.fit(Data)\n",
    "dill.dump(q5_estimator,open('Q5','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test one case\n",
    "q5_estimator = dill.load(open('Q5'))\n",
    "print q5_estimator.predict(test_json[0])\n",
    "print test_json[0]['stars']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
